{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\simple_chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided context, I believe the \"chain\" in LangChain refers to a method of combining multiple Language Models (LLMs) or other information sources into a single, cohesive system. The term \"chain\" likely indicates that these models or sources are being linked together to create a more powerful and robust chatbot.\n",
      "\n",
      "In this sense, the chain might represent a sequence or network of LLMs and retrieval systems working in concert to provide more accurate and comprehensive responses to user queries. This could involve using one model to retrieve relevant information, another to generate text based on that information, and yet another to refine or correct the output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate#PromptTemplate LangChain me ek helper class hai jo LLM ke liye prompts \n",
    "#ko dynamically generate karne ke liye use hota hai.\n",
    "from langchain_core.documents import Document#from langchain_core.documents import Document LangChain me ek bahut important class hai, \n",
    "#jo text + metadata ko represent karne ke liye use hota hai.\n",
    "from langchain_core.runnables import  #RunnablePassthrough LangChain 2024+ (LCEL) ka ek powerful utility hai, \n",
    "#jo input ko bina badle aage pass kar deta hai.\n",
    "\n",
    "# 1. LLM Load \n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "\n",
    "# 2. Dummy Docs\n",
    "docs = [Document(page_content=\"LangChain helps build chatbots using LLMs and retrieval.\")]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. Embeddings + Chroma\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectordb = Chroma.from_documents(splits, embedding=embeddings)\n",
    "\n",
    "# 4. Retriever\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# 5. Prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful AI assistant.\n",
    "Answer the question using ONLY the given context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 6. NEW RAG PIPELINE (RunnableGraph)\n",
    "def format_docs(docs):#Retriever se list of Document objects aate hain , Aap unka sirf text extract karke join kar rahe ho\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,#Left side (context) → pehle retriever chalega → fir format_docs → result prompt me jayega\n",
    "#Right side (question) → input as-is (same user query) pass hoga prompt ko\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt  #Template variables {context} & {question} fill honge, Final prompt LLM ko bheja jayega\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 7. Ask Question\n",
    "query = \"What is chain in langchain?\"\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "print(\"Answer:\", response.content) \n",
    "\n",
    "#In LangChain, a Document is a structured container that stores text (page_content) along with optional metadata.\n",
    "# It is used in RAG pipelines for splitting, embedding, storing, and retrieving context.\n",
    "\n",
    "#RunnablePassthrough is a LangChain LCEL utility that forwards the input unchanged to the next step. \n",
    "#It is essential when building multi-branch pipelines where part of the input needs preprocessing \n",
    "#while another part must pass through untouched.\n",
    "\n",
    "#“Ek reusable template jo aapke LLM prompt ko dynamic banata hai, jisme aap variables inject kar sakte ho jaise {question} aur {context}. \n",
    "# Isse LLM ko har query ke liye customized prompt bhejna easy ho jata hai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
