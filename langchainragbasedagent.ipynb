{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24cb3cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_15940\\2902224754.py:58: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_15940\\2902224754.py:70: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run(query)   # use run() instead of invoke()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to use the Knowledge Base tool to access and summarize the provided document.  I don't have access to any documents yet, so I need that information first.\n",
      "\n",
      "Action: Knowledge Base\n",
      "\n",
      "Action Input:  Please provide the document you wish me to summarize.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe provided text is about the Solar System.  It describes its composition (Sun, planets, moons, asteroids, comets, meteoroids, dwarf planets), the relative sizes and locations of its components, and the characteristics of each component type.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now have the necessary information from the Observation. I can now summarize the document.\n",
      "\n",
      "Final Answer: The document describes our Solar System, outlining its major components: the Sun, planets (both inner rocky and outer gas giants), moons, asteroids, comets, meteoroids, and dwarf planets.  It details the relative sizes and positions of these components and provides a general overview of their characteristics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent Response:\n",
      " The document describes our Solar System, outlining its major components: the Sun, planets (both inner rocky and outer gas giants), moons, asteroids, comets, meteoroids, and dwarf planets.  It details the relative sizes and positions of these components and provides a general overview of their characteristics.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install dependencies\n",
    "# pip install langchain langchain_community langchain-google-genai chromadb\n",
    "\n",
    "import os\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Prepare Documents & Vector Store\n",
    "# -------------------------------\n",
    "\n",
    "# Load documents (replace with your file path)\n",
    "loader = TextLoader(\"solar_system.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Store in Chroma\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embeddings)\n",
    "\n",
    "# Create Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Define RAG Tool\n",
    "# -------------------------------\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0),\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Knowledge Base\",\n",
    "        func=rag_chain.run,\n",
    "        description=\"Use this tool to answer questions from the uploaded documents.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Initialize Agent\n",
    "# -------------------------------\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # correct arg name\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Run Agent\n",
    "# -------------------------------\n",
    "\n",
    "query = \"Summarize the document for me.\"\n",
    "response = agent.run(query)   # use run() instead of invoke()\n",
    "\n",
    "print(\"Agent Response:\\n\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
